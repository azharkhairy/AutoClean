{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNwuKr3wFns0hwH0Oc5yb1t",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/azharkhairy/AutoClean/blob/main/VGG16_as_the_feature_extractor_in_AutoML.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install tensorflow"
      ],
      "metadata": {
        "id": "6tD7scSwBIrT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install keras_tuner"
      ],
      "metadata": {
        "id": "3hgWlidqA_Tr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "70727183-9def-41d8-d537-8df985a86f04"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting keras_tuner\n",
            "  Downloading keras_tuner-1.3.5-py3-none-any.whl (176 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/176.1 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.4/176.1 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m176.1/176.1 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from keras_tuner) (23.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from keras_tuner) (2.27.1)\n",
            "Collecting kt-legacy (from keras_tuner)\n",
            "  Downloading kt_legacy-1.0.5-py3-none-any.whl (9.6 kB)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->keras_tuner) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->keras_tuner) (2023.7.22)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->keras_tuner) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->keras_tuner) (3.4)\n",
            "Installing collected packages: kt-legacy, keras_tuner\n",
            "Successfully installed keras_tuner-1.3.5 kt-legacy-1.0.5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Import the necessary libraries: TensorFlow for deep learning, VGG16 from Keras Applications for feature extraction, CIFAR-10 dataset from Keras, Support Vector Classifier (SVC) from scikit-learn for training, RandomSearch from Kerastuner for NAS, and HyperParameters for defining hyperparameters."
      ],
      "metadata": {
        "id": "rJfGALF2_gjU"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "T40lhITD-2nq"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.applications import VGG16\n",
        "from tensorflow.keras.datasets import cifar10\n",
        "from sklearn.svm import SVC\n",
        "from keras_tuner import RandomSearch\n",
        "from keras_tuner.engine.hyperparameters import HyperParameters\n",
        "import numpy as np\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load the CIFAR-10 dataset and normalize the pixel values to be between 0 and 1."
      ],
      "metadata": {
        "id": "w3f_rJOo_l7U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1: Load and preprocess CIFAR-10 dataset\n",
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
        "x_train = x_train.astype('float32') / 255.0\n",
        "x_test = x_test.astype('float32') / 255.0"
      ],
      "metadata": {
        "id": "r3tQWhFO-6nu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ad77cd0e-9f20-4ef0-bc57-57dafd973213"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170498071/170498071 [==============================] - 11s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Subsample the dataset by randomly selecting num_samples images and their corresponding labels."
      ],
      "metadata": {
        "id": "_dBxOwdb_pg8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 2: Subsample datasets from the training set\n",
        "num_samples = 1000  # Increase the number of samples for better results\n",
        "indices = np.random.choice(x_train.shape[0], num_samples, replace=False)# This line generates random indices for subsampling. The 'np.random.choice' function randomly selects 'num_samples' unique indices from the range of indices of the entire training dataset '(x_train.shape[0]' represents the total number of training samples). The 'replace=False' argument ensures that the selected indices are unique.\n",
        "# These two lines create the subsampled training data and labels based on the randomly selected indices. The training data 'x_train_subsampled' contains the images from the original training dataset '(x_train)' corresponding to the selected indices. Similarly, the labels 'y_train_subsampled' contain the labels corresponding to the selected indices from the original labels '(y_train)'.\n",
        "x_train_subsampled = x_train[indices]\n",
        "y_train_subsampled = y_train[indices]\n",
        "# By increasing 'num_samples' to 1000, you are selecting a larger subset of the training dataset for further processin and training. This can potentially enhance the performance of your model, especially if your original dataset is large and diverse. However, keep in mind that using more samples also requires more computational resources, so make sure your hardware can handle the increased workload."
      ],
      "metadata": {
        "id": "tM6v_V9i-8Ut"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create the VGG16 model with the specified parameters: include_top=False removes the fully connected layers, weights='imagenet' initializes the model with pre-trained weights, and input_shape specifies the shape of input images. Extract features from the subsampled training and test images using the VGG16 model."
      ],
      "metadata": {
        "id": "xQ5gE2X1_svs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.applications.vgg16 import preprocess_input\n",
        "from tensorflow.keras.preprocessing.image import img_to_array, array_to_img\n",
        "from tensorflow.keras.preprocessing.image import load_img\n",
        "\n",
        "# Step 3: Use VGG16 as feature extractor\n",
        "input_shape = (224, 224)  # VGG16 input image size\n",
        "x_train_features = []\n",
        "\n",
        "for img in x_train_subsampled:\n",
        "    img = array_to_img(img)  # Convert array back to image\n",
        "    img = img.resize(input_shape)  # Resize image to VGG16 input size\n",
        "    img = img_to_array(img)\n",
        "    img = preprocess_input(img)  # Preprocess the image for VGG16\n",
        "    x_train_features.append(img)\n",
        "\n",
        "x_train_features = np.array(x_train_features)  # Convert list to numpy array\n",
        "\n",
        "x_test_features = []\n",
        "\n",
        "for img in x_test:\n",
        "    img = array_to_img(img)  # Convert array back to image\n",
        "    img = img.resize(input_shape)  # Resize image to VGG16 input size\n",
        "    img = img_to_array(img)\n",
        "    img = preprocess_input(img)  # Preprocess the image for VGG16\n",
        "    x_test_features.append(img)\n",
        "\n",
        "x_test_features = np.array(x_test_features)  # Convert list to numpy array\n",
        "\n",
        "base_model = VGG16(include_top=False, weights='imagenet', input_shape=(224, 224, 3))\n",
        "x_train_features = base_model.predict(x_train_features)\n",
        "x_test_features = base_model.predict(x_test_features)\n"
      ],
      "metadata": {
        "id": "iM99Z4sP--Fl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create an SVC classifier with a linear kernel and fit it to the extracted features of the subsampled training data."
      ],
      "metadata": {
        "id": "IF4_qPyr_1-M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 4: Train SVM classifier using the extracted features\n",
        "svm_classifier = SVC(kernel='linear')\n",
        "svm_classifier.fit(x_train_features.reshape(x_train_features.shape[0], -1), y_train_subsampled)"
      ],
      "metadata": {
        "id": "h-7WMlc2_BUs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Define a function build_model that constructs a sequential neural network. The function uses the Kerastuner's HyperParameters object to define the hyperparameters: number of hidden layers (num_layers), number of units in each hidden layer (units_i), and activation functions."
      ],
      "metadata": {
        "id": "7QSn1zPW_zKk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 5: Define NAS hypermodel for architecture search\n",
        "def build_model(hp):\n",
        "    model = tf.keras.Sequential()\n",
        "    model.add(tf.keras.layers.Flatten(input_shape=x_train_features.shape[1:]))\n",
        "    for i in range(hp.Int('num_layers', 1, 3)):\n",
        "        units = hp.Int('units_' + str(i), 32, 256, step=32)\n",
        "        model.add(tf.keras.layers.Dense(units, activation='relu'))\n",
        "    model.add(tf.keras.layers.Dense(10, activation='softmax'))\n",
        "    model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "# Step 6: Perform NAS with Keras Tuner\n",
        "tuner = RandomSearch(build_model, objective='val_accuracy', max_trials=10, directory='nas_results')\n",
        "tuner.search(x_train_features, y_train_subsampled, epochs=10, validation_split=0.2)\n"
      ],
      "metadata": {
        "id": "GxitUIKL_CXc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Retrieve the best architecture found by the NAS search, and train and evaluate it using the extracted features and the original test data."
      ],
      "metadata": {
        "id": "-PNRTHwF__x8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the best model architecture found by NAS\n",
        "best_model = tuner.get_best_models(num_models=1)[0]\n",
        "\n",
        "# Train and evaluate the best model\n",
        "best_model.fit(x_train_features, y_train_subsampled, epochs=10, validation_split=0.2)\n",
        "test_loss, test_accuracy = best_model.evaluate(x_test_features, y_test)\n",
        "print(f\"Test Loss: {test_loss}, Test Accuracy: {test_accuracy}\")\n",
        "In this code, I've modified the feature extraction part to use the VGG16 model for feature extraction. Then, I've applied NAS to find the best architecture for the classifier using the extracted features. This way, you're using VGG16 as the feature extractor in your AutoML pipeline and then searching for the best classifier architecture using NAS."
      ],
      "metadata": {
        "id": "dFLzqXauATbj"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}